\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\usepackage{titling}
\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\large#1\end{center}
    \vskip0.5em}%
}

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\urlstyle{same}

\title{Comparison of solution search algorithms, for an optimal fitness plan for a pet (the ``lazy animal'' problem)}
\subtitle{Introduction to A.I. (CSCI-4511W) - Final Project}
\author{Ryan Jackson \\ jack1805@umn.edu \\ University of Minnesota}
\date{December 16, 2022}

\begin{document}
\maketitle

Link to GitHub repository for the code project:
\href{https://github.com/ryanwebjackson/csci4511w-introAI-FinalProject}{https://github.com/ryanwebjackson/csci4511w-introAI-FinalProject} 

\section{Problem Description}

For my CSCI-4511W final project, I utilized several artificial intelligence (A.I.) techniques to address the problem of optimal pet (animal) health, in terms of physical activity. This is a problem because some pets are not very physically active, and both for their well-being, and our (human beings') own reasons, we want them to live as long as reasonably possible (I am now calling this the ``lazy animal'' problem). Since there are many factors that go into this, my initial idea was to use a pet cat (agent/actor, real or simulated) and an adversarial A.I. (Mini-Max, etc.) to generate a strategy to keep the cat fit using small rewards for physical activity (a small treat for traveling a number of square feet). In exploring this idea, I realized that it may work, but several other approaches may also work. Therefore the core of the project is to run several simulations, using different A.I. techniques, and to compare the results of those simulations.

Here are some resources I referenced when doing initial research for this problem:
\begin{itemize}
    \item ``Diet and exercise patterns in pet dogs.'' (Article) \cite{slater1995diet}
    \item ``Varram'' - product doing something similar to the idea for this project: https://varram.com \cite{varram}
    \textit{They do not cite any sort of technical reference, and one would have to infer/reverse engineer how this robot is working}
    \item A difference example of pet AI - computer vision to detect animal pain: ``Facial expressions of pain in cats: the development and validation of a Feline Grimace Scale'' - used to see how A.I. can be used to determine a pet's reaction to stimulus  \cite{evangelista2019}
\end{itemize}

\section{Addressing the Problem with A.I. Techniques}

The core concept of this project is to create an adversarial AI, to generate a strategy, to keep a pet as healthy as possible. This assumes a pet which does not want to get much exercise, and an owner that does want the pet to get an optimal amount of exercise (``the lazy animal problem'').

Through iterative experimentation, several specific approaches were tried:
\begin{itemize}
    \item Mini-Max (with and without A-B pruning)
    \item Genetic algorithms
    \item Monte-Carlo Tree Search
    \item Reinforcement learning - \textit{Ran out of time}
    \item Random activity from both agents - serves as a control group - \textit{AIMA provides some of this functionality but it didn't make it into the current version of my code}
\end{itemize}

\subsection{Software}
  I made good use of the AIMA code we studied in this course and custom software I have written to enact the experiments planned for this project. 
  Though not included in the attached code, I plan to continue this project, and use and open source libraries like MushroomRL to do so.\cite{mushroom}

\section{Experiments}

I wrote custom Python software (script), using the AIMA (\cite{russell2016artificial}) code as a base. Please see the following code snippet on how to run the main script and pass a single word argument to it to configure the algorithm used.

\begin{lstlisting}
    if args[0] == "minimax":
        print("running minimax (alpha-beta pruning)...")
        RunnerMinimaxGame1.run_minimax()
    elif args[0] == "genetic":
        print("running genetic algorithm...")
        RunnerGeneticGame1.run_genetic()
    elif args[0] == "montecarlo":
        print("running monte carlo tree search...")
        RunnerMonteCarloGame1.run_montecarlo()
    else:
        print('Invalid argument passed - running nothing.')
\end{lstlisting}

Please see the GitHub URL at the top of this paper for reference to the full code.

\subsection{Performance Measures}
\textit{The `P' in PEAS}

\textit{Performance Measures, for measuring the success of a specific algorithm}
\begin{itemize}
  \item Is the move count of agent 1 greater than 0 and less than the over-fitness parameter? The higher this number in this range, the greater the performance.
  \item What is the move count of agent 2? Presume that a minimal move count is better.
  \item If breaking, or adding, food is an option in the game, assume that a lower count for this action is better.
  \item Assume that agent 1 (cat) can smell the air an unlimited number of times.
\end{itemize}

\textit{Performance Measures, for comparing different algorithms}

\begin{itemize}
  \item Method 1: Value Iteration Algorithm (RL) \cite{mohan2014}
  \textit{Time to converge}
  \item Method 2: Processor utilization
  \item Method 3: Memory requirements
\end{itemize}

\textit{I did not get these performance monitoring measures working in Python in time to submit this paper.}

\section{Analysis}

From establishing Python code examples, using the AIMA book's code as a base to build upon, I got different results from each of the algorithms, which leads me to believe that I either: didn't structure the problem appropriately or didn't run the experiments (by way of the custom code) enough (iteration number was too low). I initially thought that a "lazy animal" coupled with a human as a "competitor" would make for a great Mini-Max problem/game, but going through the aforementioned programming experience, writing out the problem, and talking it over with peers, I have come to the conclusion that this is not the best approach. Though there may be several viable approaches, I believe the best to be reinforcement learning (RL) for the following several reasons:

\begin{itemize}
  \item RL is a good approach when the true model is not known. (when data is not labelled, or when the average path to success is not known)
  \item RL is good when the goal does not change. In this case, the general goal does not change, but the specific form it takes might.
  \item RL is good at making a long sequence of complex decisions. In this case, the solution might be more complex than expected, but it certainly not as complex as a game like GO, which RL has been used to find solutions for.
\end{itemize}

Note that RL can be initialized with "demonstrations" purposeful training examples of a prescribed method on how to perform a task. In this case, a fitness plan solution could be provided by current or former pet owners, as well as crowd-sourced.

\subsection{Lessons learned on specific algorithms}

One of the algorithms I explored to solve this problem, is a class of algoritms called Genetic Algorithms (GA). One of the papers I referenced to better understand how this concept can be applied to a problem like this comes from Riechmann, 2001. \cite{RIECHMANN20011019} He says, ``These propositions are (a) every GA is a dynamic game; (b) every GA is an evolutionary game; and (c) in GA learning processes, populations tend to converge towards a Nash equilibrium.''. I believe this to be applicable because an animal can't be eating all the time, playing all the time, sleeping all the time, etc. - there must be a balance. The balance is what is found by seeking the Nash equilibrium, especially over time, and with a little randomness applied to a learning algorithm.
  
\section{Future plans}

I would like to make use of an animal activity tracker device, and one of these A.I. (classes of) algorithms, to make this a real-world project. I ran out of time in the semester to utilize it, but have purchased a tracking device for my pet dog, and hope to use the data it generates to develop fitness plans (over time).

In addition, I would like to clean this project up, by doing better data analysis and metric collection/base-lining, and by presenting the conclusions and analyses by using interactive Python notebooks, similar to the approach we used in the final assignment of the semester.

\newpage
\bibliographystyle{plain}
\raggedright
\bibliography{main}

\end{document}
